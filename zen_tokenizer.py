# Tokenizer for my large language model "zen"
# the Tokenizer will be a version of byte pair encoding!

from collections import Counter, deque
from functools import lru_cache

